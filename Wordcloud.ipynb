{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688c5b87",
   "metadata": {},
   "source": [
    "# CREATING WORDCLOUDS BASED ON A TWITTER USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f6bac8",
   "metadata": {},
   "source": [
    "## INSTALLATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d766e30",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ef690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy,csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from wordcloud import WordCloud\n",
    "from tools import plot_opinion_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74c0da",
   "metadata": {},
   "source": [
    "## BEARER TOKEN & CLIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = \"<write_your_individual_bearer_token>\"\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294138df",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_user=client.get_user(username='Dior')\n",
    "print(my_user.data.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13369ca0",
   "metadata": {},
   "source": [
    "## CODE TO COLLECT USER'S TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31304c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_id='348379865'\n",
    "tweet_fields_to_get=['id','text',\"created_at\"]\n",
    "response= tweepy.Paginator(client.get_users_tweets ,user_id ,exclude=['retweets','replies'],max_results=100,limit=5)\n",
    "\n",
    "for tweet in response.flatten(limit=500):\n",
    "    for field in tweet_fields_to_get:\n",
    "        print(field,':',tweet[field])\n",
    "\n",
    "        \n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14037f55",
   "metadata": {},
   "source": [
    "## SAVE & READ TWEETS IN A CSV FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f572fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fw=open('dior.csv','w',encoding='utf8')\n",
    "my_writer=csv.writer(fw,lineterminator='\\n') \n",
    "my_writer.writerow(tweet_fields_to_get) \n",
    "for tweet in response.flatten():  \n",
    "    new_row=[] \n",
    "    for field in tweet_fields_to_get: \n",
    "        new_row.append(tweet[field])\n",
    "\n",
    "    my_writer.writerow(new_row)\n",
    "    \n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ae1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dior.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "dior_df = pd.read_csv('dior.csv', usecols = ['text']).replace(r'\\\\n|\\\\u|http[^\\s]*','', regex=True)\n",
    "print(dior_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce822d1c",
   "metadata": {},
   "source": [
    "## CREATING 3 WORDCLOUDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dior_dict={\n",
    "    'adjective':{},\n",
    "    'noun':{},\n",
    "    'verb':{}}\n",
    "\n",
    "for text in dior_df['text'] : \n",
    "    lower_text = text.lower()\n",
    "    words = word_tokenize(lower_text)\n",
    "    tagged_words = nltk.pos_tag(words) \n",
    "\n",
    "    for word, pos in tagged_words: \n",
    "        if pos.startswith('JJ'):\n",
    "            dior_dict['adjective'][word] = dior_dict['adjective'].get(word, 0) + 1\n",
    "        if pos.startswith('NN'):\n",
    "            dior_dict['noun'][word] = dior_dict['noun'].get(word, 0) + 1\n",
    "        if pos.startswith('VB'):\n",
    "            dior_dict['verb'][word] = dior_dict['verb'].get(word, 0) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef519d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dior_tweets=dior_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739cf6d",
   "metadata": {},
   "source": [
    "### Wordcloud with adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_opinion_cloud(dior_tweets, 'adjective')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe854242",
   "metadata": {},
   "source": [
    "### Wordcloud with nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74abb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_opinion_cloud(dior_tweets, 'noun')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef38163",
   "metadata": {},
   "source": [
    "### Wordcloud with verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d85a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_opinion_cloud(dior_tweets, 'verb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
